{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torchvision\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm_notebook, tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### 定义初始参数及激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "inputs = np.array([3, 5])\n",
    "weights = {'h11': np.array([2, 4]),\n",
    "           'h12': np.array([4, -5]),\n",
    "           'h21': np.array([-1, 1]),\n",
    "           'h22': np.array([2, 2]),\n",
    "           'out': np.array([-3, 7])}\n",
    "\n",
    "def tanh(x):\n",
    "    return (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### 逐层计算神经网络输出\n",
    "1. 首先是第一个隐藏层，你需要将输入层的数据与隐藏层的权重相乘、求和、并输入到激活函数中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# hidden_11_value = tanh((inputs * weights['h11']).sum())\n",
    "# hidden_12_value = tanh((inputs * weights['h12']).sum())\n",
    "# hidden_1_output = np.array([hidden_11_value, hidden_12_value])\n",
    "\n",
    "hidden_11_value = tanh(inputs.dot(weights['h11']).sum())\n",
    "hidden_12_value = tanh(inputs.dot(weights['h12']).sum())\n",
    "hidden_1_output = np.array([hidden_11_value, hidden_12_value])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "2. 接下来是第二个隐藏层，这一层的操作与上一层完全相同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hidden_21_value = tanh(hidden_1_output.dot(weights['h21']).sum())\n",
    "hidden_22_value = tanh(hidden_1_output.dot(weights['h22']).sum())\n",
    "hidden_2_output = np.array([hidden_21_value, hidden_22_value])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "3. 最后是输出层，此时只有一个节点需要运算，且无需添加激活函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "output = (hidden_2_output * weights['out']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8920827403683393"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### CIFAR-10 图像分类过程\n",
    "##### 定义对图像的各种变换操作，包括把array转换为tensor，对图像做正则化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# transforms.Compose主要是用于常见的一些图形变换，例如裁剪、旋转\n",
    "# 遍历list数组，对img依次执行每个transforms操作\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.4914, 0.48216, 0.44653),\n",
    "                                                     (0.24703, 0.24349, 0.26159))])\n",
    "train_set = torchvision.datasets.CIFAR10(\n",
    "    root='./data/cifar10-data/', train=True,\n",
    "    download=True, transform=transform\n",
    ")\n",
    "test_set = torchvision.datasets.CIFAR10(\n",
    "    root='./data/cifar10-data/',\n",
    "    download=True, transform=transform\n",
    ")\n",
    "\n",
    "# 用来把训练数据分成多个小组，此函数每次抛出一组数据。\n",
    "train_loader = torch.utils.data.DataLoader(train_set,\n",
    "                                           batch_size=16,\n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set,\n",
    "                                          batch_size=16,\n",
    "                                          shuffle=False)\n",
    "train_set.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 把图片进行可视化展示\n",
    "def imshow(inp, title=None):\n",
    "    fig = plt.figure(figsize=(30, 30))\n",
    "    # 转换成图片的维度\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    # 对图片进行标准化\n",
    "    inp = std * inp + mean\n",
    "    # 整个图片数组的值限制在a_min 与 a_max之间\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    # 对图片进行可视化展示\n",
    "    plt.imshow(inp, )\n",
    "\n",
    "# 获取一个batch的数据\n",
    "inputs, classes = next(iter(train_loader))\n",
    "# 以网格展示，作用是将若干幅图拼成一幅图像\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "imshow(out, title=[train_set.classes[x] for x in classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### 搭建简单的神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(32 * 32 * 3, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 500)\n",
    "        self.fc3 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.relu(self.fc3(x))\n",
    "\n",
    "net = Net()\n",
    "# 定义损失函数-交叉熵\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# 定义优化器， 将神经网络的参数都传入优化器，并定义学习率\n",
    "optimizer = optim.Adam(net.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### 神经网络的训练步骤\n",
    "1. 大for循环-epochs，用于管理一套数据循环训练多少遍<br>\n",
    "2. 小for循环-step，用于以batch_size为单位，从dataloader中调取数据\n",
    "3. 清空优化器的梯度\n",
    "4. 读入data, label，并进行形状转换\n",
    "5. 运行模型前向传播过程\n",
    "6. 基于模型输出生成最终结果\n",
    "7. 计算损失\n",
    "8. 基于损失计算梯度\n",
    "9. 基于梯度更新参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "since = time.time()\n",
    "net.train()\n",
    "# 1. 用于管理一套数据循环训练多少遍\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch: {epoch} / {num_epochs}')\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    # 2. 从trainloader里循环取出每一批次数据，\n",
    "    for data in tqdm_notebook(train_loader):\n",
    "        # 3. 清空优化器梯度\n",
    "        optimizer.zero_grad()\n",
    "        # 4. 读入data, label，并进行形状转换\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.view(-1, 32 * 32 * 3)\n",
    "        # 5. 运行模型前向传播过程\n",
    "        outputs = net(inputs)\n",
    "        # 6. 基于模型输出生成最终结果\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        # 7. 计算损失\n",
    "        loss = criterion(outputs, labels)\n",
    "        # 8. 基于损失计算梯度\n",
    "        loss.backward()\n",
    "        # 9. 基于梯度更新参数\n",
    "        optimizer.step()\n",
    "\n",
    "        # 一个批次数据的损失函数的计算\n",
    "        running_loss += loss.items() * inputs.size(0)\n",
    "        # 一个批次数据准确率的计算\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = running_loss / train_loader.dataset.data.shape[0]\n",
    "    epoch_acc = running_corrects.double() / train_loader.dataset.data.shape[0]\n",
    "    print('Train loss: {:.4f}, Acc: {:.4f'.format(epoch_loss, epoch_acc))\n",
    "    print('-' * 50)\n",
    "time_elapsed = time.time() - since\n",
    "print('Training complete in {:.0f}m {:.0f}s'\n",
    "      .format(time_elapsed // 60, time_elapsed % 60))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### 模型测评\n",
    "模型测评过程中的数据导入、前向传播过程与训练过程基本相同，可以参照训练过程来写\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "correct = total = 0\n",
    "net.eval()\n",
    "for data in tqdm_notebook(test_loader):\n",
    "    # 1. 数据导入\n",
    "    inputs, labels = data\n",
    "    inputs = inputs.view(-1, 32 * 32 * 3)\n",
    "    # 前向传播\n",
    "    outputs = net(inputs)\n",
    "\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('The testing set accuracy of the network is: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
